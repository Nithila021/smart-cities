================================================================================
RESEARCH 3: UNIFIED SYSTEM DESIGN & IMPLEMENTATION PLAN
Combining Augment Analysis + ChatGPT Architecture Recommendations
================================================================================

################################################################################
#                           CHANGELOG / UPDATES                                 #
#  New decisions go here. Old content preserved below for reference.           #
################################################################################

================================================================================
UPDATE 2026-01-26: DATABASE SCHEMA DECISIONS (Nithila + Augment)
================================================================================

STATUS: DECIDED - Ready for implementation

## SUMMARY OF KEY DECISIONS:

| Decision                     | Choice                          | Rationale                    |
|------------------------------|--------------------------------|------------------------------|
| Amenities cache strategy     | Append + refresh on stale      | Avoid stale data, track provenance |
| Risk cache demographic       | Separate rows per demographic  | Clean queries, indexable     |
| Grid system                  | Simple grid for MVP, H3 later  | Faster to implement now      |
| Cache invalidation           | Hybrid (time + event-based)    | Balance freshness vs compute |
| Store crime counts           | Yes, raw + weighted            | Enables confidence + debug   |

--------------------------------------------------------------------------------
TABLE 1: AMENITIES (Smart POI Cache)
--------------------------------------------------------------------------------

PURPOSE: Dynamic cache for geocoded locations. NOT a manually curated list.

WORKFLOW:
  1. User provides: address, place name, or coordinates
  2. System checks amenities table (cache hit?)
  3. Cache MISS → Query external API → Insert → Return
  4. Cache HIT + fresh (<30 days) → Return cached
  5. Cache HIT + stale (>30 days) → Return cached, queue background refresh

SCHEMA:
```sql
CREATE TABLE amenities (
    id SERIAL PRIMARY KEY,

    -- Core identity
    name VARCHAR(255) NOT NULL,
    location GEOGRAPHY(POINT, 4326) NOT NULL,

    -- Classification
    amenity_type VARCHAR(50) NOT NULL,     -- Primary: bar, restaurant, park, transit
    amenity_tags JSONB,                     -- Additional: ["nightclub", "live_music"]

    -- External API linkage
    external_id VARCHAR(100),               -- place_id (Google) or osm_id (Overpass)
    external_api_source VARCHAR(30),        -- 'google_places', 'overpass', 'nominatim'

    -- Operational data
    operating_hours JSONB,                  -- {"mon": "09:00-22:00", ...}
    neighborhood VARCHAR(100),

    -- Cache management
    created_at TIMESTAMP DEFAULT NOW(),
    last_verified_at TIMESTAMP DEFAULT NOW(),
    verification_count INTEGER DEFAULT 1,   -- How many times queried

    -- Risk modifiers (ML can populate this)
    risk_modifier DECIMAL(3,2) DEFAULT 1.0  -- 1.2 = increases risk, 0.8 = decreases
);

-- Indexes
CREATE INDEX idx_amenity_location ON amenities USING GIST(location);
CREATE INDEX idx_amenity_type ON amenities(amenity_type);
CREATE INDEX idx_amenity_external ON amenities(external_api_source, external_id);
```

--------------------------------------------------------------------------------
TABLE 2: RISK_CACHE (Demographic-Specific ML-Computed Risk Scores)
--------------------------------------------------------------------------------

PURPOSE: Pre-computed risk scores PER DEMOGRAPHIC GROUP based on ACTUAL
         victimization data for that demographic in that location.

CORE INNOVATION (PATENT-WORTHY):
  - For demographic_group = "women" → count crimes WHERE victim_sex = 'F'
  - For demographic_group = "children" → count crimes WHERE victim_age < 18
  - For demographic_group = "elderly" → count crimes WHERE victim_age >= 65
  - For demographic_group = "general" → count ALL crimes (baseline)

RISK CALCULATION FORMULA:
```
risk_score(location, time, demographic) =
    COUNT(crimes WHERE victim matches demographic
          AND location IN grid_cell
          AND time matches hour_bucket/day_type)
    × time_decay_weight (recent = 1.0, 30-90 days = 0.7, 90+ days = 0.4)
    × ML_adjustments (K-Means zone, DBSCAN hotspot, KDE density)
```

WHY SEPARATE ROWS PER DEMOGRAPHIC (not JSONB):
  - Clean queries: WHERE demographic_group = 'women'
  - Indexable: Can index on demographic_group column
  - Explicit: No parsing JSONB
  - Trade-off: 4x storage (acceptable)

GRID SYSTEM DECISION:
  - MVP: Simple grid using ROUND(lat, 3), ROUND(lon, 3) → ~111m cells
  - Future: H3 hexagons resolution 9 (~174m) when scaling
  - grid_cell_id format: "40.758_-73.985"

CACHE INVALIDATION:
  - Hybrid: time-based (expires_at) + event-based (is_stale flag)
  - Daily job marks cells as stale if new crimes added
  - Background job recomputes stale cells

SCHEMA:
```sql
CREATE TABLE risk_cache (
    id SERIAL PRIMARY KEY,

    -- Location identifiers
    grid_cell_id VARCHAR(20) NOT NULL,      -- "40.758_-73.985" or H3 index
    center_point GEOGRAPHY(POINT, 4326),

    -- Clustering context (from existing ML models)
    zone_id INTEGER,                         -- K-Means zone (0-29)
    dbscan_cluster_id INTEGER,               -- NULL if not in hotspot
    density_level VARCHAR(10),               -- 'low', 'medium', 'high'

    -- Temporal context
    hour_bucket INTEGER NOT NULL,            -- 0-23
    day_type VARCHAR(10) NOT NULL,           -- 'weekday', 'weekend'

    -- CORE: Demographic-specific (THIS IS THE INNOVATION)
    demographic_group VARCHAR(20) NOT NULL,  -- 'general', 'women', 'children', 'elderly'

    -- Crime counts
    raw_crime_count INTEGER,                 -- Total crimes matching demographic
    weighted_crime_count DECIMAL(10,2),      -- After time-decay applied
    crime_breakdown JSONB,                   -- {"sexual": 5, "assault": 12, ...}

    -- Computed scores
    risk_score DECIMAL(5,2) NOT NULL,        -- 0-100 normalized
    confidence DECIMAL(3,2),                 -- Based on sample_size

    -- Cache management
    computed_at TIMESTAMP DEFAULT NOW(),
    expires_at TIMESTAMP,
    data_version INTEGER DEFAULT 1,
    is_stale BOOLEAN DEFAULT FALSE,

    -- Composite unique constraint
    UNIQUE(grid_cell_id, hour_bucket, day_type, demographic_group)
);

-- Indexes for fast lookups
CREATE INDEX idx_risk_location ON risk_cache(grid_cell_id);
CREATE INDEX idx_risk_demographic ON risk_cache(demographic_group);
CREATE INDEX idx_risk_time ON risk_cache(hour_bucket, day_type);
CREATE INDEX idx_risk_staleness ON risk_cache(is_stale) WHERE is_stale = TRUE;
CREATE INDEX idx_risk_spatial ON risk_cache USING GIST(center_point);
```

--------------------------------------------------------------------------------
TABLE 3: CRIME_INCIDENTS (Core Crime Data) - From Original Design
--------------------------------------------------------------------------------

SCHEMA (unchanged from original):
```sql
CREATE TABLE crime_incidents (
    id SERIAL PRIMARY KEY,
    location GEOGRAPHY(POINT, 4326),
    crime_type VARCHAR(50),
    crime_category VARCHAR(50),          -- sexual, harassment, assault, theft, property
    severity_weight DECIMAL(3,2),
    occurred_at TIMESTAMP,
    day_of_week INTEGER,
    hour_of_day INTEGER,
    victim_demographics JSONB,           -- {age_group, sex, race}
    precinct VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_crime_location ON crime_incidents USING GIST(location);
CREATE INDEX idx_crime_time ON crime_incidents(occurred_at);
CREATE INDEX idx_crime_type ON crime_incidents(crime_category);
```

--------------------------------------------------------------------------------
TABLE 4: DEMOGRAPHIC_IMPACT_WEIGHTS (Configurable Multipliers)
--------------------------------------------------------------------------------

PURPOSE: Research-backed multipliers for crimes that disproportionately
         affect certain demographics (e.g., sexual crimes → women = 1.8x)

SCHEMA (unchanged from original):
```sql
CREATE TABLE demographic_impact_weights (
    id SERIAL PRIMARY KEY,
    crime_category VARCHAR(50),
    demographic_group VARCHAR(50),
    impact_weight DECIMAL(3,2),
    source VARCHAR(100),                 -- Research citation
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE UNIQUE INDEX idx_demo_unique
    ON demographic_impact_weights(crime_category, demographic_group);
```

--------------------------------------------------------------------------------
OPEN QUESTIONS (To Decide)
--------------------------------------------------------------------------------

[ ] Time-decay weights: Store in DB or compute on-the-fly?
    - Option A: Add decay_weight column to crime_incidents
    - Option B: Compute during risk calculation (current preference)

[ ] Demographic age mappings (NYPD data):
    - Children: <18 only? or include 18-24?
    - Elderly: 65+ only? or include 55-64?

[ ] Multi-city support: Add city_code to tables now or later?

[ ] crime_breakdown in risk_cache: By crime_type (granular) or crime_category (5 types)?

================================================================================
END OF UPDATE 2026-01-26
================================================================================


################################################################################
#                     ORIGINAL RESEARCH 3 CONTENT BELOW                        #
################################################################################

DESIGN PHILOSOPHY (CORE ANCHOR)
--------------------------------------------------------------------------------
"Crime prediction is location-time based. Risk interpretation is demographic-context based."

Your system:
✗ Does NOT predict criminals
✗ Does NOT label people  
✓ DOES estimate how crime patterns affect different user groups differently

================================================================================
PART 1: UNIFIED 6-LAYER ARCHITECTURE
================================================================================

┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER A: Global Crime Intelligence (Data Ingestion)                        │
│  ├── Historical crime incidents (NYPD data)                                 │
│  ├── 311 Complaints data (NEW - broken windows indicator)                   │
│  ├── Real amenity/POI data via Overpass API (REPLACE fake data)            │
│  └── Street lighting, transit proximity (NEW)                               │
│  OUTPUT: Clean, validated, multi-source crime events                        │
│  DATABASE: PostgreSQL + PostGIS (UPGRADE from CSV/in-memory)                │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER B: Spatio-Temporal Risk Modeling (ML Engine)                         │
│  ├── CURRENT: KDE, K-Means, DBSCAN                                          │
│  ├── ADD: XGBoost for feature importance + interpretability                 │
│  ├── ADD: Time-decay weighting (recent crimes matter more)                  │
│  ├── FUTURE: ST-GCN for advanced spatiotemporal patterns                    │
│  OUTPUT: Continuous Risk(lat, lon, time) per crime type                     │
│  KEY CHANGE: From hard clusters → continuous risk surfaces                  │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER C: Crime-Type Risk Decomposition                                     │
│  OUTPUT: RiskVector(place, time) = {                                        │
│      sexual_offense_risk,                                                   │
│      harassment_risk,                                                       │
│      violent_assault_risk,                                                  │
│      theft_risk,                                                            │
│      property_crime_risk                                                    │
│  }                                                                          │
│  WHY: Enables demographic-specific interpretation                           │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER D: Demographic Impact & Exposure Layer (YOUR CORE IDEA)              │
│  ├── User Context: demographics, group_size, time_window, venue_type        │
│  ├── Impact Matrix: How crime types affect different groups                 │
│  ├── Exposure Multiplier: f(group_size, time, venue_type)                   │
│  └── Uncertainty Quantification (NEW - confidence intervals)                │
│  THIS IS WHERE YOUR UNIQUE VALUE PROPOSITION LIVES                          │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER E: Personalized Risk Decision Engine                                 │
│  FORMULA:                                                                   │
│  PersonalizedRisk = Σ [ CrimeRisk_type(place,time)                          │
│                        × DemographicImpact(type,user)                       │
│                        × ExposureMultiplier(user,context) ]                 │
│                                                                             │
│  ConfidenceScore = f(data_density, recency, sample_size)                    │
│                                                                             │
│  ANSWERS: "Is Bar A safer for women at 8PM or 11PM?"                        │
│           "Which park is safer for children in the morning?"                │
│           "How confident is this assessment?"                               │
└─────────────────────────────────────────────────────────────────────────────┘
                                    ↓
┌─────────────────────────────────────────────────────────────────────────────┐
│  LAYER F: Explanation & Visualization Layer                                 │
│  ├── LLM Integration: Natural language safety explanations (NEW)            │
│  ├── Mapbox GL JS: 3D visualization, WebGL performance (UPGRADE)            │
│  ├── Uncertainty visualization: Show confidence in scores                   │
│  └── Temporal patterns: Interactive time-based risk views                   │
└─────────────────────────────────────────────────────────────────────────────┘

================================================================================
PART 2: DEMOGRAPHIC IMPACT MATRIX (Formalized)
================================================================================

| Crime Type      | Children   | Women      | Elderly    | General    |
|-----------------|------------|------------|------------|------------|
| Sexual Offense  | VERY HIGH  | HIGH       | MEDIUM     | LOW        |
| Harassment      | LOW        | HIGH       | MEDIUM     | MEDIUM     |
| Violent Assault | MEDIUM     | HIGH       | VERY HIGH  | HIGH       |
| Theft/Robbery   | LOW        | MEDIUM     | HIGH       | MEDIUM     |
| Property Crime  | LOW        | LOW        | LOW        | MEDIUM     |

IMPLEMENTATION NOTE:
- This matrix does NOT change actual crime rates
- It changes HOW MUCH a crime type matters to a specific user group
- Weights can be tuned based on research/victimization statistics

EXPOSURE MULTIPLIERS:
| Context                          | Multiplier |
|----------------------------------|------------|
| Woman alone, bar, after 10PM     | 1.5x       |
| Woman in group, bar, after 10PM  | 0.8x       |
| Child with adults, park, daytime | 0.5x       |
| Child alone, anywhere            | 2.0x       |
| Elderly alone, night             | 1.8x       |

================================================================================
PART 3: TECHNOLOGY UPGRADE MAPPING
================================================================================

CURRENT STATE → TARGET STATE

1. DATA LAYER
   CSV files + Pandas      →  PostgreSQL + PostGIS
   Fake amenity data       →  Real OSM data via Overpass API
   NYPD only               →  NYPD + 311 + Lighting + Transit

2. ML LAYER
   K-Means (30 clusters)   →  K-Means + XGBoost ensemble
   DBSCAN                  →  DBSCAN + time-decay weighting
   KDE                     →  KDE with crime-type separation
   No uncertainty          →  Bayesian confidence intervals
   FUTURE                  →  ST-GCN / Ada-GCNLSTM

3. API LAYER
   /safety-score           →  /safety-score + confidence + breakdown
   /hotspots               →  /hotspots + temporal filtering
   NEW                     →  /personalized-risk (demographic-aware)
   NEW                     →  /compare-places (bar vs bar)
   NEW                     →  /safe-times (time window recommendations)

4. FRONTEND LAYER
   React-Leaflet           →  Mapbox GL JS (or keep Leaflet + deck.gl)
   Basic heatmaps          →  Crime-type-specific layers
   No explanations         →  LLM-powered natural language insights
   No uncertainty viz      →  Confidence indicators on scores

================================================================================
PART 4: IMPLEMENTATION PHASES
================================================================================

PHASE 1: DATA FOUNDATION (Week 1-2)
────────────────────────────────────
Priority: HIGH | Effort: MEDIUM

Tasks:
[ ] Set up PostgreSQL + PostGIS database
[ ] Design schema for crimes, amenities, risk_scores
[ ] Migrate existing NYPD CSV data to database
[ ] Implement Overpass API integration for real POI data
[ ] Add 311 complaints data from NYC Open Data
[ ] Create data validation and cleaning pipeline

Deliverables:
- Working database with spatial indexing
- Real amenity data replacing fake data
- Multi-source data integration

PHASE 2: ML MODEL UPGRADES (Week 3-4)
─────────────────────────────────────
Priority: HIGH | Effort: HIGH

Tasks:
[ ] Separate crime analysis by type (create RiskVector)
[ ] Add time-decay weighting to existing models
[ ] Implement XGBoost classifier for crime type prediction
[ ] Add confidence intervals to safety scores
[ ] Create continuous risk surfaces (upgrade from hard clusters)
[ ] Implement feature importance extraction

Deliverables:
- Crime-type-specific risk modeling
- Uncertainty quantification on all scores
- Interpretable feature importance

PHASE 3: DEMOGRAPHIC PERSONALIZATION ENGINE (Week 5-6)
──────────────────────────────────────────────────────
Priority: HIGH | Effort: MEDIUM

Tasks:
[ ] Implement Demographic Impact Matrix (configurable weights)
[ ] Create Exposure Multiplier calculation
[ ] Build PersonalizedRisk formula implementation
[ ] Add user context input (group size, demographics, venue type)
[ ] Create /personalized-risk API endpoint
[ ] Create /compare-places API endpoint
[ ] Create /safe-times API endpoint

Deliverables:
- Demographic-aware risk scoring
- Place comparison functionality
- Time-window recommendations

PHASE 4: LLM INTEGRATION (Week 7-8)
───────────────────────────────────
Priority: MEDIUM | Effort: MEDIUM

Tasks:
[ ] Set up OpenAI/Claude API integration
[ ] Design prompt templates for safety explanations
[ ] Create explanation generation service
[ ] Implement context-aware recommendation generation
[ ] Add natural language query interface
[ ] Cache common explanations for performance

Deliverables:
- Natural language safety explanations
- Personalized recommendations in plain English
- Conversational query support

PHASE 5: VISUALIZATION UPGRADE (Week 9-10)
──────────────────────────────────────────
Priority: MEDIUM | Effort: MEDIUM

Tasks:
[ ] Evaluate Mapbox GL JS vs keeping React-Leaflet + deck.gl
[ ] Implement crime-type-specific map layers
[ ] Add uncertainty visualization (confidence bands/colors)
[ ] Create temporal slider for time-based risk views
[ ] Add 3D visualization for crime density
[ ] Optimize performance for large datasets

Deliverables:
- Enhanced interactive mapping
- Uncertainty visualization
- Time-based exploration

================================================================================
PART 5: NEW API ENDPOINTS SPECIFICATION
================================================================================

ENDPOINT: POST /personalized-risk
─────────────────────────────────
Request:
{
  "location": {"lat": 40.7128, "lon": -74.0060},
  "user_profile": {
    "demographic": "woman",        // woman, child, elderly, general
    "age_group": "25-34",
    "group_size": 1,               // 1 = alone
    "group_composition": "solo"    // solo, mixed, same_gender
  },
  "context": {
    "time": "2024-01-15T23:00:00",
    "venue_type": "bar",           // bar, park, street, transit
    "planned_duration": 120        // minutes
  }
}

Response:
{
  "personalized_risk_score": 67,
  "confidence": 0.78,
  "risk_breakdown": {
    "sexual_offense": {"base": 12, "adjusted": 18},
    "harassment": {"base": 25, "adjusted": 38},
    "assault": {"base": 15, "adjusted": 23},
    "theft": {"base": 20, "adjusted": 24}
  },
  "safer_alternatives": {
    "safer_time": "19:00-21:00",
    "time_risk_reduction": 35,
    "nearby_safer_venues": [...]
  },
  "explanation": "Harassment incidents increase after 10 PM in this area..."
}

ENDPOINT: POST /compare-places
──────────────────────────────
Request:
{
  "places": [
    {"name": "Bar A", "lat": 40.7128, "lon": -74.0060},
    {"name": "Bar B", "lat": 40.7150, "lon": -74.0080}
  ],
  "user_profile": {...},
  "time": "2024-01-15T22:00:00"
}

Response:
{
  "comparison": [
    {
      "name": "Bar A",
      "personalized_risk": 67,
      "confidence": 0.78,
      "dominant_risk_type": "harassment"
    },
    {
      "name": "Bar B",
      "personalized_risk": 45,
      "confidence": 0.82,
      "dominant_risk_type": "theft"
    }
  ],
  "recommendation": "Bar B shows 33% lower risk for your profile...",
  "safer_choice": "Bar B"
}

ENDPOINT: GET /safe-times
─────────────────────────
Request:
{
  "location": {"lat": 40.7128, "lon": -74.0060},
  "user_profile": {...},
  "date": "2024-01-15"
}

Response:
{
  "time_windows": [
    {"start": "06:00", "end": "09:00", "risk": 25, "label": "LOW"},
    {"start": "09:00", "end": "17:00", "risk": 35, "label": "LOW"},
    {"start": "17:00", "end": "21:00", "risk": 52, "label": "MEDIUM"},
    {"start": "21:00", "end": "00:00", "risk": 78, "label": "HIGH"},
    {"start": "00:00", "end": "06:00", "risk": 85, "label": "HIGH"}
  ],
  "safest_window": {"start": "06:00", "end": "09:00"},
  "explanation": "Morning hours show lowest harassment risk..."
}

================================================================================
PART 6: DATABASE SCHEMA (PostgreSQL + PostGIS)
================================================================================

-- Core crime incidents table
CREATE TABLE crime_incidents (
    id SERIAL PRIMARY KEY,
    location GEOGRAPHY(POINT, 4326),
    crime_type VARCHAR(50),
    crime_category VARCHAR(50),  -- sexual, harassment, assault, theft, property
    severity_weight DECIMAL(3,2),
    occurred_at TIMESTAMP,
    day_of_week INTEGER,
    hour_of_day INTEGER,
    victim_demographics JSONB,
    precinct VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW()
);

-- Spatial index for fast queries
CREATE INDEX idx_crime_location ON crime_incidents USING GIST(location);
CREATE INDEX idx_crime_time ON crime_incidents(occurred_at);
CREATE INDEX idx_crime_type ON crime_incidents(crime_category);

-- Real amenities/POIs
CREATE TABLE amenities (
    id SERIAL PRIMARY KEY,
    location GEOGRAPHY(POINT, 4326),
    name VARCHAR(255),
    amenity_type VARCHAR(50),  -- bar, restaurant, park, transit_station
    operating_hours JSONB,
    neighborhood VARCHAR(100)
);

-- Pre-computed risk scores (cached)
CREATE TABLE risk_cache (
    id SERIAL PRIMARY KEY,
    grid_cell_id VARCHAR(50),  -- H3 or custom grid
    center_point GEOGRAPHY(POINT, 4326),
    crime_category VARCHAR(50),
    hour_bucket INTEGER,       -- 0-23
    day_type VARCHAR(10),      -- weekday, weekend
    risk_score DECIMAL(5,2),
    confidence DECIMAL(3,2),
    sample_size INTEGER,
    computed_at TIMESTAMP,
    expires_at TIMESTAMP
);

-- Demographic impact weights (configurable)
CREATE TABLE demographic_impact_weights (
    id SERIAL PRIMARY KEY,
    crime_category VARCHAR(50),
    demographic_group VARCHAR(50),
    impact_weight DECIMAL(3,2),
    source VARCHAR(100),       -- research citation
    updated_at TIMESTAMP
);

================================================================================
PART 7: CODE MAPPING - What Changes Where
================================================================================

BACKEND FILES TO MODIFY:

1. data_loader.py
   - REMOVE: Fake amenity data generation
   - ADD: PostgreSQL connection
   - ADD: Overpass API integration for real POIs
   - ADD: 311 data loader

2. crime_analyzer.py
   - MODIFY: Separate analysis by crime_category
   - ADD: Time-decay weighting function
   - ADD: Confidence interval calculation
   - ADD: XGBoost model alongside existing models

3. NEW FILE: personalization_engine.py
   - ADD: DemographicImpactMatrix class
   - ADD: ExposureMultiplier calculator
   - ADD: PersonalizedRiskCalculator
   - ADD: PlaceComparator

4. NEW FILE: llm_service.py
   - ADD: OpenAI/Claude integration
   - ADD: Prompt templates for explanations
   - ADD: Explanation caching

5. app.py (Flask routes)
   - ADD: /personalized-risk endpoint
   - ADD: /compare-places endpoint
   - ADD: /safe-times endpoint
   - MODIFY: Existing endpoints to include confidence

FRONTEND FILES TO MODIFY:

1. Map component
   - ADD: Crime-type layer toggles
   - ADD: Confidence visualization
   - ADD: Time slider

2. NEW: PersonalizedRiskForm component
   - ADD: User profile input
   - ADD: Context selection

3. NEW: PlaceComparison component
   - ADD: Side-by-side comparison UI

================================================================================
PART 8: QUICK WINS (Implement This Week)
================================================================================

1. REPLACE FAKE AMENITY DATA (1 day)
   - Use Overpass API to get real bars, parks, transit stops
   - Immediate improvement to data quality

2. ADD CRIME CATEGORY SEPARATION (1 day)
   - Split analysis into: sexual, harassment, assault, theft, property
   - Foundation for demographic impact matrix

3. ADD BASIC CONFIDENCE SCORE (1 day)
   - confidence = f(sample_size, recency)
   - Show users how reliable scores are

4. CREATE DEMOGRAPHIC IMPACT MATRIX CONFIG (1 day)
   - JSON config file with weights
   - Easy to tune without code changes

5. ADD TIME-DECAY TO EXISTING MODELS (1 day)
   - Recent crimes weighted higher
   - More relevant predictions

================================================================================
PART 9: RESEARCH CITATIONS & JUSTIFICATION
================================================================================

Architecture justified by:
- ST-GCN: "Spatio-Temporal Graph Convolutional Networks" (AAAI 2018)
- Ada-GCNLSTM: Adaptive cross-city crime prediction (2024)
- Demographic impact: FBI Victimization Statistics methodology
- Uncertainty: Bayesian Deep Learning for crime prediction (2023)

Key papers to cite:
1. "Crime Prediction Using Machine Learning" - IEEE Smart Cities 2024
2. "Spatiotemporal Crime Hotspot Detection" - ACM SIGSPATIAL 2023
3. "Ethical Considerations in Predictive Policing" - Nature 2022

================================================================================
SUMMARY: WHAT CHANGED VS WHAT STAYED
================================================================================

✗ REMOVED (Old Approach):
- Hard cluster boundaries
- Exact demographic matching
- Single overall safety score
- No uncertainty
- Fake amenity data

✓ PRESERVED (Your Core Ideas):
- Demographic-wise analysis
- Group vs solo considerations
- Time-based decisions
- Place comparison (bar vs bar, park vs park)
- User-specific risk computation

✓ ADDED (Upgrades):
- Continuous risk surfaces
- Crime-type-aware personalization
- Confidence scores
- LLM explanations
- Real data sources
- Proper database

================================================================================
END OF RESEARCH 3
================================================================================


